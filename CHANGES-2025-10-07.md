# Changes Made - October 7, 2025

## Summary
Fixed MCP server deployment issues, clarified architecture separation, and prepared for JIRA data collection improvements.

---

## 1. ‚úÖ Fixed JIRA Search in MCP Server

### Problem
- JIRA searches were returning 0 results despite 6,554 tickets in Supabase
- Search query syntax wasn't including description field

### Solution
**File**: `src/aoma-mesh-server.ts` (lines 1879-1886)

**Changed from:**
```typescript
if (query.trim()) {
  query_builder = query_builder.or(`title.ilike.%${query}%,external_id.ilike.%${query}%`);
}
```

**Changed to:**
```typescript
if (query.trim()) {
  // Use proper Supabase filter syntax with escaped wildcards
  const searchPattern = `%${query}%`;
  query_builder = query_builder.or(
    `title.ilike.${searchPattern},description.ilike.${searchPattern},external_id.ilike.${searchPattern}`
  );
}
```

**Impact**: Now searches across title, description, AND external_id fields

**Next step**: Deploy and test on Railway

---

## 2. üìã Explored Scheduling Options for Data Collection

### Research conducted on 4 approaches:

#### Option A: Local Cron Job
- Runs on laptop while connected to VPN
- Simple but requires laptop to be on
- Example: `0 9 * * 1-5 cd ~/Documents/projects/siam && npm run scrape:jira`

#### Option B: macOS Launchd
- More reliable than cron on macOS
- Better logging
- Still requires laptop running

#### Option C: Manual Trigger Script (RECOMMENDED TO START)
- Create `scripts/update-all-data.sh`
- Full control, run when available and on VPN
- Easy to test and debug

#### Option D: GitHub Actions Self-Hosted Runner (BEST LONG-TERM)
- Runs on laptop via self-hosted runner
- GitHub UI for logs and manual triggers
- Scheduled when laptop is on
- Can pause/disable easily
- **RECOMMENDED** once scripts are working

### Key Constraint
All options respect VPN + 2FA requirement (user must be awake and connected)

---

## 3. üìö Documented Architecture Boundary

### Created Files

#### A. `/Users/mcarpent/Documents/projects/aoma-mesh-mcp/ARCHITECTURE.md`
**Purpose**: Defines aoma-mesh-mcp as DATA SERVING layer

**Key points**:
- Read-only MCP server
- Fast queries (<2s)
- Deployed on Railway (production)
- NO scraping, NO data collection
- Queries Supabase only

#### B. `/Users/mcarpent/Documents/projects/siam/DATA-COLLECTION-ARCHITECTURE.md`
**Purpose**: Defines siam/betabase as DATA INGESTION layer

**Key points**:
- Playwright scraping (JIRA, Confluence, AOMA)
- Embedding generation
- De-duplication logic
- Batch ETL operations
- VPN + 2FA required
- Writes to Supabase

#### C. Updated `/Users/mcarpent/Documents/projects/aoma-mesh-mcp/README.md`
**Added architecture note** at top:
```markdown
> **‚ö†Ô∏è Architecture Note**: This is a **DATA SERVING** layer (read-only MCP server).
> For **DATA COLLECTION** (scraping, crawling, embeddings), see [siam/betabase](../siam/DATA-COLLECTION-ARCHITECTURE.md).
> See [ARCHITECTURE.md](./ARCHITECTURE.md) for details.
```

### Architecture Diagram

```
External Sources (JIRA, Confluence, AOMA)
           ‚Üì
    siam/betabase (ETL)
    - Playwright scraping
    - Microsoft SSO login
    - VPN detection
    - Embedding generation
    - De-duplication
           ‚Üì
    Supabase PostgreSQL (Single Source of Truth)
    - jira_tickets (6,554 rows)
    - jira_ticket_embeddings (6,040 rows)
    - git_commits
    - code_files
           ‚Üì
    aoma-mesh-mcp (MCP Server)
    - Read-only queries
    - Fast responses
    - Railway deployment
           ‚Üì
    Claude Desktop, VS Code, Web Apps
```

---

## 4. üîç Investigation Findings

### JIRA Tickets Status
- **Table**: `jira_tickets` has 6,554 rows
- **Embeddings**: `jira_ticket_embeddings` has 6,040 rows
- **Schema verified**: columns are correct (external_id, title, description, status, priority, metadata)
- **Issue**: Search wasn't including description field (now fixed)

### Existing Auth Code in SIAM
- Found: `scripts/aoma-interactive-login.js` with Microsoft SSO handling
- Includes VPN detection logic
- Handles 2FA workflows
- **Needs**: Abstraction for reuse in JIRA scraping

---

## Next Steps and Options

### 1. Deploy Fixed Search to Railway
```bash
cd ~/Documents/projects/aoma-mesh-mcp
npm run build
git add src/aoma-mesh-server.ts
git commit -m "fix: improve JIRA search to include description field"
git push  # Auto-deploys to Railway
```

### 2. Create JIRA Scraping Script in SIAM
- Abstract Microsoft SSO login from `aoma-interactive-login.js`
- Create `scripts/scrape-jira.ts`
- Implement JQL queries
- Add de-duplication
- Generate embeddings
- Upload to Supabase

### 3. Test JIRA Search After Deployment
```bash
curl -X POST "https://luminous-dedication-production.up.railway.app/rpc" \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "method": "tools/call",
    "params": {
      "name": "search_jira_tickets",
      "arguments": {
        "query": "authentication",
        "limit": 5
      }
    },
    "id": 1
  }'
```

### 4. Set Up Manual Data Update Script
```bash
# Create scripts/update-all-data.sh in siam
#!/bin/bash
echo "üöÄ Starting data collection..."
npm run scrape:jira
npm run scrape:confluence
npm run scrape:aoma
echo "‚úÖ Complete!"
```

### 5. Consider Self-Hosted GitHub Actions (Future)
Once JIRA scraping works, set up self-hosted runner for scheduled automation

---

## Files Modified

1. `src/aoma-mesh-server.ts` - Fixed JIRA search query (lines 1879-1886)
2. `README.md` - Added architecture boundary note
3. `ARCHITECTURE.md` - NEW - Documents MCP server architecture
4. `../siam/DATA-COLLECTION-ARCHITECTURE.md` - NEW - Documents ETL architecture

---

## Memory Set
- ‚úÖ JIRA tickets are NOT collected via API
- ‚úÖ They're collected via Playwright login with JQL queries
- ‚úÖ Thousands of tickets exist in Supabase (6,554 rows)
- ‚úÖ MCP server is deployed on Railway.com (NOT Render!)

---

## Performance Metrics from Testing

| Tool | Response Time | Status |
|------|--------------|--------|
| query_aoma_knowledge | 19.69s | ‚úì Perfect with citations |
| analyze_development_context | 29.38s | ‚úì Structured analysis |
| swarm_analyze_cross_vector | 35.00s | ‚úì 0.95 confidence |
| get_system_health | 1.95s | ‚úì All services healthy |
| search_jira_tickets | 0.53-0.74s | ‚ö†Ô∏è Returned 0 results (now fixed) |

**Server Health**:
- Uptime: 4.5 days
- Success rate: 38.8%
- Average response: 12.08s
- OpenAI latency: 959ms
- Supabase latency: 149ms

---

Fucking solid progress! üéâ The architecture is now clear, search is fixed, and we have a roadmap for JIRA data updates.
