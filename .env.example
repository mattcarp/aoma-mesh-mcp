# AOMA Mesh MCP Server Environment Variables
# Copy this file to .env or .env.local and update with your actual values

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
AOMA_ASSISTANT_ID=asst_your-aoma-assistant-id-here
OPENAI_VECTOR_STORE_ID=vs_your-vector-store-id-here

# Supabase Configuration  
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-supabase-anon-key-here
SUPABASE_SERVICE_ROLE_KEY=your-supabase-service-key-here

# Server Configuration
NODE_ENV=development
LOG_LEVEL=info
HTTP_PORT=3333
MAX_RETRIES=3
TIMEOUT_MS=30000

# CORS Configuration
# Comma-separated list of allowed origins, e.g. https://your-frontend.com,https://admin.your-frontend.com
# Use * only for local development, never in production!
ALLOWED_ORIGINS=*

# LangSmith Configuration (Optional - for tracing and monitoring)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your-langsmith-api-key-here
LANGCHAIN_PROJECT=aoma-mesh-mcp
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# --- SSE MCP Transport Configuration ---
# Enables SSE MCP transport endpoint
ENABLE_SSE_TRANSPORT=false
# SSE endpoint path
SSE_ENDPOINT_PATH=/mcp/sse
# Comma-separated allowed origins for SSE CORS (optional)
SSE_CORS_ORIGINS=

# --- Prometheus Metrics & Correlation IDs ---
# Enable Prometheus metrics collection and expose a Prometheus scrape endpoint
# Set to true in production to integrate with Prometheus/Grafana
ENABLE_PROMETHEUS_METRICS=false

# Path to expose Prometheus metrics in text exposition format
# Change if you need a custom path due to ingress or platform constraints
PROMETHEUS_ENDPOINT_PATH=/metrics/prometheus

# Prefix for all Prometheus metric names for this service
# Helps avoid collisions across services and eases dashboard filtering
PROMETHEUS_METRICS_PREFIX=aoma_mesh_

# HTTP header name used to carry request correlation IDs
# Middleware will honor an incoming header (e.g., from a gateway) or generate one
REQUEST_CORRELATION_HEADER=x-correlation-id
